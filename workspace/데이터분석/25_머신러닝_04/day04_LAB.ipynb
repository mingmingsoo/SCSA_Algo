{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70112b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1faed",
   "metadata": {},
   "source": [
    "### Ensemble - Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83bd324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d1e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer() \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer['data'],\n",
    "                                                           cancer['target'],\n",
    "                                                           stratify=cancer['target'],\n",
    "                                                           random_state=0)\n",
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db7848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "869b8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                        ('dt3', dt3), ('dt5', dt5)])\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                        ('dt3', dt3), ('dt5', dt5)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f293d1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy: 98.12%\n",
      "hard Test Accuracy: 95.10%\n",
      "\n",
      "soft Train Accuracy: 99.53%\n",
      "soft Test Accuracy: 95.80%\n",
      "\n",
      "knn1 Train Accuracy: 94.60%\n",
      "knn1 Test Accuracy: 91.61%\n",
      "\n",
      "knn2 Train Accuracy: 95.77%\n",
      "knn2 Test Accuracy: 91.61%\n",
      "\n",
      "lr Train Accuracy: 96.71%\n",
      "lr Test Accuracy: 93.71%\n",
      "\n",
      "dt3 Train Accuracy: 97.65%\n",
      "dt3 Test Accuracy: 93.01%\n",
      "\n",
      "dt5 Train Accuracy: 100.00%\n",
      "dt5 Test Accuracy: 93.01%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_train, y_train)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_train, y_train)*100\n",
    "    test_score = model.score(x_test, y_test)*100\n",
    "    print(f'{name} Train Accuracy: {train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy: {test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe1898",
   "metadata": {},
   "source": [
    "### Ensemble - Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2a3162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.951048951048951)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5).fit(x_train, y_train)\n",
    "model.score(x_train,y_train), model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0018c1",
   "metadata": {},
   "source": [
    "### Ensemble - Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5036c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.958041958041958)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_train, y_train)\n",
    "model.score(x_train,y_train), model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7abf7b",
   "metadata": {},
   "source": [
    "### Ensemble - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4920444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()),\n",
    "               ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                          final_estimator=LogisticRegression())\n",
    "\n",
    "model.fit(x_train,y_train).score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feef144",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ce70f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.01, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.01, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),\n",
       "             param_grid={'learning_rate': [0.01, 0.01, 0.1],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 300, 500]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boston = pd.read_csv('../data/boston.csv')\n",
    "x = boston.iloc[:, :-1]\n",
    "y = boston['price']\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate' : [0.01, 0.01, 0.1],\n",
    "    'max_depth' : [3, 4, 5],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, params).fit(x, y)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "372264b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142930</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.391113</td>\n",
       "      <td>0.022348</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.643083</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163073</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.622736</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.250098</td>\n",
       "      <td>0.339023</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.508461</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.804976</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.569607</td>\n",
       "      <td>0.245518</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.812511</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.805867</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.607504</td>\n",
       "      <td>0.211341</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200673</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.234089</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575356</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741932</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.582341</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.519629</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.034250</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753964</td>\n",
       "      <td>0.763259</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105823</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.241819</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.146147</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.412794</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.685282</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.167816</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.622736</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.250098</td>\n",
       "      <td>0.339023</td>\n",
       "      <td>0.321260</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.551336</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.804976</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.569607</td>\n",
       "      <td>0.245518</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.862558</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.805867</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.607504</td>\n",
       "      <td>0.211341</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.205280</td>\n",
       "      <td>0.015231</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.234089</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.680454</td>\n",
       "      <td>0.061762</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741932</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.582341</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.519629</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.032447</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753964</td>\n",
       "      <td>0.763259</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105823</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.241819</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.126722</td>\n",
       "      <td>0.008922</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.783812</td>\n",
       "      <td>0.857255</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.570781</td>\n",
       "      <td>0.394882</td>\n",
       "      <td>0.669760</td>\n",
       "      <td>0.166581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.403223</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.784743</td>\n",
       "      <td>0.841977</td>\n",
       "      <td>0.750611</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.664103</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.786592</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.841031</td>\n",
       "      <td>0.755053</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>0.171089</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.184447</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.786304</td>\n",
       "      <td>0.824756</td>\n",
       "      <td>0.703891</td>\n",
       "      <td>0.579527</td>\n",
       "      <td>0.298256</td>\n",
       "      <td>0.638547</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.515749</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.791083</td>\n",
       "      <td>0.826134</td>\n",
       "      <td>0.701348</td>\n",
       "      <td>0.554677</td>\n",
       "      <td>0.277191</td>\n",
       "      <td>0.630087</td>\n",
       "      <td>0.199827</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.856015</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.826204</td>\n",
       "      <td>0.700705</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.272191</td>\n",
       "      <td>0.628711</td>\n",
       "      <td>0.202375</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.196869</td>\n",
       "      <td>0.017253</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.742419</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.626869</td>\n",
       "      <td>0.534051</td>\n",
       "      <td>0.078034</td>\n",
       "      <td>0.550210</td>\n",
       "      <td>0.250678</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.873490</td>\n",
       "      <td>0.103288</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740558</td>\n",
       "      <td>0.767554</td>\n",
       "      <td>0.630651</td>\n",
       "      <td>0.526032</td>\n",
       "      <td>0.071061</td>\n",
       "      <td>0.547171</td>\n",
       "      <td>0.253007</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.493714</td>\n",
       "      <td>0.073454</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.630505</td>\n",
       "      <td>0.525423</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>0.546923</td>\n",
       "      <td>0.253167</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.142930      0.011582         0.000000        0.000000   \n",
       "1        0.391113      0.022348         0.000597        0.000796   \n",
       "2        0.643083      0.020727         0.000000        0.000000   \n",
       "3        0.163073      0.006892         0.000397        0.000487   \n",
       "4        0.508461      0.021249         0.000000        0.000000   \n",
       "5        0.812511      0.014279         0.000000        0.000000   \n",
       "6        0.200673      0.016901         0.003748        0.005974   \n",
       "7        0.575356      0.011950         0.006251        0.007656   \n",
       "8        1.034250      0.074271         0.000573        0.001146   \n",
       "9        0.146147      0.011246         0.000361        0.000723   \n",
       "10       0.412794      0.046763         0.000611        0.000821   \n",
       "11       0.685282      0.020962         0.002239        0.001931   \n",
       "12       0.167816      0.009534         0.000383        0.000765   \n",
       "13       0.551336      0.036702         0.000800        0.000750   \n",
       "14       0.862558      0.010156         0.001326        0.001108   \n",
       "15       0.205280      0.015231         0.000199        0.000399   \n",
       "16       0.680454      0.061762         0.007026        0.008207   \n",
       "17       1.032447      0.054000         0.001163        0.002325   \n",
       "18       0.126722      0.008922         0.003538        0.006126   \n",
       "19       0.403223      0.031969         0.000495        0.000627   \n",
       "20       0.786592      0.114610         0.001078        0.000992   \n",
       "21       0.184447      0.024229         0.000547        0.000777   \n",
       "22       0.515749      0.015930         0.000198        0.000396   \n",
       "23       0.856015      0.032847         0.000401        0.000801   \n",
       "24       0.196869      0.017253         0.003127        0.006254   \n",
       "25       0.873490      0.103288         0.001196        0.001615   \n",
       "26       1.493714      0.073454         0.002688        0.003386   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.01               3                100   \n",
       "1                 0.01               3                300   \n",
       "2                 0.01               3                500   \n",
       "3                 0.01               4                100   \n",
       "4                 0.01               4                300   \n",
       "5                 0.01               4                500   \n",
       "6                 0.01               5                100   \n",
       "7                 0.01               5                300   \n",
       "8                 0.01               5                500   \n",
       "9                 0.01               3                100   \n",
       "10                0.01               3                300   \n",
       "11                0.01               3                500   \n",
       "12                0.01               4                100   \n",
       "13                0.01               4                300   \n",
       "14                0.01               4                500   \n",
       "15                0.01               5                100   \n",
       "16                0.01               5                300   \n",
       "17                0.01               5                500   \n",
       "18                 0.1               3                100   \n",
       "19                 0.1               3                300   \n",
       "20                 0.1               3                500   \n",
       "21                 0.1               4                100   \n",
       "22                 0.1               4                300   \n",
       "23                 0.1               4                500   \n",
       "24                 0.1               5                100   \n",
       "25                 0.1               5                300   \n",
       "26                 0.1               5                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634855   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741932   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753964   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "15  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634855   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741932   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753964   \n",
       "18  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.783812   \n",
       "19  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.784743   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.779593   \n",
       "21  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.786304   \n",
       "22  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.791083   \n",
       "23  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.794082   \n",
       "24  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.742419   \n",
       "25  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740558   \n",
       "26  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740573   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.688112           0.220861           0.325642   \n",
       "1            0.865449           0.691776           0.484630   \n",
       "2            0.867336           0.738485           0.535428   \n",
       "3            0.622736           0.314555           0.374583   \n",
       "4            0.804976           0.656688           0.506602   \n",
       "5            0.805867           0.693576           0.544797   \n",
       "6            0.560458           0.290091           0.377049   \n",
       "7            0.763737           0.582341           0.477830   \n",
       "8            0.763259           0.622998           0.498162   \n",
       "9            0.688112           0.220861           0.325642   \n",
       "10           0.865449           0.691776           0.484630   \n",
       "11           0.867336           0.738485           0.535428   \n",
       "12           0.622736           0.314555           0.374583   \n",
       "13           0.804976           0.656688           0.506602   \n",
       "14           0.805867           0.693576           0.544797   \n",
       "15           0.560458           0.290091           0.377049   \n",
       "16           0.763737           0.582341           0.477830   \n",
       "17           0.763259           0.622998           0.498162   \n",
       "18           0.857255           0.742070           0.570781   \n",
       "19           0.841977           0.750611           0.554167   \n",
       "20           0.841031           0.755053           0.552954   \n",
       "21           0.824756           0.703891           0.579527   \n",
       "22           0.826134           0.701348           0.554677   \n",
       "23           0.826204           0.700705           0.550373   \n",
       "24           0.769675           0.626869           0.534051   \n",
       "25           0.767554           0.630651           0.526032   \n",
       "26           0.767495           0.630505           0.525423   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -0.175309         0.336265        0.310029               24  \n",
       "1            0.314734         0.622589        0.197722                9  \n",
       "2            0.380540         0.656949        0.175110                4  \n",
       "3           -0.250098         0.339023        0.321260               22  \n",
       "4            0.123035         0.569607        0.245518               13  \n",
       "5            0.224560         0.607504        0.211341               11  \n",
       "6           -0.234089         0.325673        0.305927               26  \n",
       "7            0.032308         0.519629        0.265394               20  \n",
       "8            0.105823         0.548841        0.241819               16  \n",
       "9           -0.175309         0.336265        0.310029               24  \n",
       "10           0.314734         0.622589        0.197722                9  \n",
       "11           0.380540         0.656949        0.175110                4  \n",
       "12          -0.250098         0.339023        0.321260               22  \n",
       "13           0.123035         0.569607        0.245518               13  \n",
       "14           0.224560         0.607504        0.211341               11  \n",
       "15          -0.234089         0.325673        0.305927               26  \n",
       "16           0.032308         0.519629        0.265394               20  \n",
       "17           0.105823         0.548841        0.241819               16  \n",
       "18           0.394882         0.669760        0.166581                1  \n",
       "19           0.389019         0.664103        0.168187                2  \n",
       "20           0.379286         0.661583        0.171089                3  \n",
       "21           0.298256         0.638547        0.189767                6  \n",
       "22           0.277191         0.630087        0.199827                7  \n",
       "23           0.272191         0.628711        0.202375                8  \n",
       "24           0.078034         0.550210        0.250678               15  \n",
       "25           0.071061         0.547171        0.253007               18  \n",
       "26           0.070617         0.546923        0.253167               19  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "report = pd.DataFrame(gs.cv_results_)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cfe6226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283b2025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6697600256867121"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0ce217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e732e71",
   "metadata": {},
   "source": [
    "### Ensemble(Voting)을 활용한 분류 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7456bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9c5c0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7601677148846959)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = xgb.XGBClassifier(objective='reg:squarederror')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "p_train = model.predict(x_train)\n",
    "p_test = model.predict(x_test)\n",
    "\n",
    "r2_score(y_train, p_train), r2_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "462d89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4272\n",
      "[LightGBM] [Info] Number of data points in the train set: 426, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.626761\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9918813367894838, 0.8215397238164611)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "}\n",
    "\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_eval)\n",
    "\n",
    "p_train = model.predict(x_train, num_iteration=model.best_iteration)\n",
    "p_test = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "r2_score(y_train, p_train), r2_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f201322-8bb4-40ee-aa17-e0988bc0d6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
